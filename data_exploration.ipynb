{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from src.load_scripts import load_h5_dataset\n",
    "from src.visualization import plot_spectra\n",
    "\n",
    "path = Path('data/Marsikov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set({\"array.slicing.split_large_chunks\": False})\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(img[::15, ::15, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = {\n",
    "    'albite':      ( 71, 213, 213),\n",
    "    'quartz':      ( 85,   0, 255),\n",
    "    'muscovite':   (251, 119, 255),\n",
    "    'spessartine': (190,  95,  41),\n",
    "    'orthoclase':  (255,  32, 103),\n",
    "    'biotite':     (255, 170,   0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5_dataset(dataset_path: Path):\n",
    "    for file_path in dataset_path.glob('**/*.h5'):\n",
    "        try:\n",
    "            f = h5py.File(file_path, \"r\")\n",
    "            f = f[list(f.keys())[0]]\n",
    "            f = f[list(f.keys())[0]]\n",
    "            f = f['libs']\n",
    "            print('    Loading dimensions...', end='', flush=True)\n",
    "            dim = [max(f['metadata']['X']) + 1, max(f['metadata']['Y']) + 1]\n",
    "            print(' Done!', flush=True)\n",
    "\n",
    "            print('    Loading spectra...', end='', flush=True)\n",
    "            X = da.from_array(f['data'])\n",
    "            print(' Done!', flush=True)\n",
    "\n",
    "            print('    Loading wavelengths...', end='', flush=True)\n",
    "            wavelengths = da.from_array(f['calibration'])\n",
    "            print(' Done!', flush=True)\n",
    "\n",
    "            print('    Reshaping spectra...', end='', flush=True)\n",
    "            X = da.reshape(X, dim + [-1])\n",
    "            X[::2, :] = X[::2, ::-1]\n",
    "            print(' Done!', flush=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('\\n[WARNING] Failed to load file {} with error message: {}. Skipping!'.format(file_path, e), flush=True)\n",
    "            continue\n",
    "\n",
    "        print('    Loading true labels...', end='', flush=True)\n",
    "        img = np.asarray(Image.open(dataset_path / 'y_true.png'))\n",
    "        flat = img.reshape(-1, img.shape[2])\n",
    "        y = np.zeros(flat.shape[0])\n",
    "        for i, val in tqdm(enumerate(legend.values(), start=1)):\n",
    "            y[(flat == val).all(axis=1)] = i\n",
    "        y = y.reshape(img.shape[:-1])\n",
    "\n",
    "        return X, y, wavelengths, dim\n",
    "    raise RuntimeError('Failed to load! No valid file found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, wavelengths, dim = load_h5_dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensities = X.sum(axis=2).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the images\n",
    "image1 = np.array((y - y.min()) / y.max() * 256 , dtype='uint8')  # Higher-resolution image\n",
    "image2 = np.array((intensities - intensities.min()) / intensities.max() * 256, dtype='uint8')  # Lower-resolution image\n",
    "\n",
    "del X, y\n",
    "\n",
    "# Detect SIFT keypoints and descriptors in both images\n",
    "sift = cv2.SIFT_create()\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(image1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(image2, None)\n",
    "\n",
    "# Match descriptors using BFMatcher\n",
    "bf = cv2.BFMatcher()\n",
    "matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Apply ratio test to filter good matches\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.75 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Find the transformation using the matched keypoints\n",
    "src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "\n",
    "# Warp the lower-resolution image to match the higher-resolution one\n",
    "aligned_image = cv2.warpPerspective(image2, M, (image1.shape[1], image1.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = np.array((y - y.min()) / y.max() * 256 , dtype='uint8')  # Higher-resolution image\n",
    "image2 = np.array((intensities - intensities.min()) / intensities.max() * 256, dtype='uint8')  # Lower-resolution image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(ncols=2)\n",
    "ax[0].imshow(image1)\n",
    "ax[1].imshow(image2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dims = []\n",
    "for original_length, new_length in zip(\n",
    "    libs_map.shape, \n",
    "    [int(x  * 1.5) for x in libs_map.shape]\n",
    "):\n",
    "    new_dims.append(np.linspace(0, original_length-1, new_length))\n",
    "\n",
    "coords = np.meshgrid(*new_dims, indexing='ij')\n",
    "upscaled_libs_map = map_coordinates(libs_map, coords)\n",
    "\n",
    "upscaled_libs_map = quantile_process_map(\n",
    "    input_map=upscaled_libs_map,\n",
    "    rotate=True,\n",
    "    transpose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find size of image1\n",
    "sz = libs_match.shape\n",
    "\n",
    "libs_image = libs_match.copy()\n",
    "icp_image = template.copy()\n",
    " \n",
    "# Define the motion model\n",
    "warp_mode = cv2.MOTION_AFFINE\n",
    " \n",
    "# Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "    warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "else:\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    " \n",
    "# Specify the number of iterations.\n",
    "number_of_iterations = 5000\n",
    " \n",
    "# Specify the threshold of the increment\n",
    "# in the correlation coefficient between two iterations\n",
    "termination_eps = 1e-10\n",
    " \n",
    "# Define termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    " \n",
    "# Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "(cc, warp_matrix) = cv2.findTransformECC (icp_image,libs_image,warp_matrix, warp_mode, criteria)\n",
    " \n",
    "if warp_mode == cv2.MOTION_HOMOGRAPHY:\n",
    "# Use warpPerspective for Homography\n",
    "    libs_image_aligned = cv2.warpPerspective(\n",
    "        libs_image, \n",
    "        warp_matrix, \n",
    "        (sz[1],sz[0]), \n",
    "        flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP\n",
    "    )\n",
    "else :\n",
    "# Use warpAffine for Translation, Euclidean and Affine\n",
    "    libs_image_aligned = cv2.warpAffine(\n",
    "        libs_image, \n",
    "        warp_matrix, \n",
    "        (sz[1],sz[0]), \n",
    "        flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP\n",
    "    )\n",
    " \n",
    "# Show final results\n",
    "fig,ax = plt.subplots(ncols=3)\n",
    "ax[0].imshow(icp_image)\n",
    "ax[1].imshow(libs_image)\n",
    "ax[2].imshow(libs_image_aligned)\n",
    "\n",
    "print(np.corrcoef(\n",
    "    icp_image.reshape(-1),\n",
    "    libs_image.reshape(-1)\n",
    ")[0,1])\n",
    "print(np.corrcoef(\n",
    "    icp_image.reshape(-1),\n",
    "    libs_image_aligned.reshape(-1)\n",
    ")[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
